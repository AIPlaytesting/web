{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This is AI Playtesting We aim to use reinforcement learning AI Agents to solve card game balance. Our Method We created a tool for designers to balance a game called Slay the Spire. Design : build your deck by adding Slay the Spire cards, or even customize your cards. Training : train the AI agent using Deep Reinforcement Learning algorithms. Playtest : let AI playtest and display statistics for identifying imbalance and updating the rules of the game.","title":"Home"},{"location":"#this-is-ai-playtesting","text":"We aim to use reinforcement learning AI Agents to solve card game balance.","title":"This is AI Playtesting"},{"location":"#our-method","text":"We created a tool for designers to balance a game called Slay the Spire. Design : build your deck by adding Slay the Spire cards, or even customize your cards. Training : train the AI agent using Deep Reinforcement Learning algorithms. Playtest : let AI playtest and display statistics for identifying imbalance and updating the rules of the game.","title":"Our Method"},{"location":"ai/","text":"AI","title":"AI"},{"location":"ai/#ai","text":"","title":"AI"},{"location":"demo/","text":"Application Demo (21 minutes)","title":"Demo"},{"location":"demo/#application-demo-21-minutes","text":"","title":"Application Demo (21 minutes)"},{"location":"design/","text":"Design First Half: Provide scenarios for the development team to make the AI Our goal is to make an AI playtest agent that could learn to play a turn-based card game and provide valuable feedback to the game designer. Valuable feedback includes: Game Balance Economy Balance Game Mechanics Game too easy/hard Dominant strategy Card Design Deck Building To deliver that feedback, the very first thing we need to do is make sure that our AI knows how to play the game, and master the game. The first deck that I provided: Strike+ : Deal 9 damage *4 Defend : Gain 5 Block *3 Shrug it off : Gain 8 Block. Draw 1 card. Pommel Strike+ : Deal 10 damage. Draw 2 cards Flex : Gain 2 strength, and lost it at the end of the game Thunderclap : Deal 4 damage and apply 1 vulnerable to all enemies Twin Strike+ : Deal 7 damage twice Bludgeon : Deal 32 damage This deck has a 100% win rate when a human player plays it. This means our AI should have a win rate highly close to 100%. This makes it easier for our development team to see how good our AI is. This deck is: Easy It only has 8 different cards, 1 debuff for the boss, and 1 buff for the player. It only has 13 cards, each card gets recycled very fast. Bludgeon A very useful card that dealt a significant amount of damage Flex 0 cost card that can boost up attack cards. This card should be played first when drawing it, this will be a good reference for us to see our AI\u2019s strategy. We are anticipating our AI will figure out the correct combo of playing Flex Thunderclap and then another attack card. What do we learn from this deck? Actually, this is not the first version of the deck, in the very first version, we have bludgeon+ and bash+ instead of bludgeon and thunderclap. And we had a 100% win rate. The reason we decided to change that is that the player could always win by only playing attack cards. If we use the deck to test our AI, it could have a very high win rate even if our AI is not sophisticated enough. After changing to the current deck, a random bot will not work in this situation. The player needs to manage when to play attack and when to play defense. During the human playtest result, the ending margin of player HP and boss HP are pretty close, close to zero. How does our AI perform on this deck? Our AI finally got nearly 90% of the win rate on this deck, however, it is still not willing to play flex before other attack cards. In the designer\u2019s mind, we thought that always playing flex at the beginning of the turn is an obvious move. The AI is not following that. The second deck that I provided: Bash : Deal 8 damage. Apply 2 Vulnerable. Shockwave : Apply 3 Weak and Vulnerable to ALL enemies. Exhaust. Sword Boomerang+ : Deal 3 damage to a random enemy 4 times. *2 Cleave+ : Deal 11 damage to ALL enemies. *2 Iron Wave : Gain 5 Block. Deal 5 damage. *2 Feed+ : Deal 12 damage. If this kills a non-minion enemy, gain 4 permanent Max HP. Exhaust. Clothesline+ : Deal 14 damage. Apply 3 Weak. Heavy Blade+ : Deal 14 damage. Strength affects Heavy Blade 5 times. *2 Impervious : Gain 30 Block. Exhaust. Disarm : Enemy loses 2 Strength. Exhaust. Double Tap : This turn, your next Attack is played twice. Uppercut : Deal 13 damage. Apply 1 Weak. Apply 1 Vulnerable. According to our playtest, we also secured a 100% win rate on this deck. This deck is a lot harder than the first deck, it involves more exhaust cards. Exhaust card means card that only could play once in the entire boss fight. This deck is: Hard It has 13 different cards, each of them has unique usability. It has more buffs. It only has 2 to 3 defensive cards with less block value. Majority of the cards cost 2 energy. Double Tap A powerful card that empowers the next attack cards. Exhaust cards Can only play once in the entire game. It provides a deeper task to the AI to figure out which turn is the best turn to play the exhaust cards. What do we learn from this deck? When the AI could win the game, it will not try to maximize its damage in every single turn. So the difficulty of a deck is related to the performance of the AI, if the AI faces a much more difficult deck, it will try to maximize its damage. How does our AI perform on this deck? Our AI finally got 87% of the win rate on this deck, which is pretty good. The AI seems more likely to use 2 same attack cards instead of double tap and then attack card. The results are the same.","title":"Design"},{"location":"design/#design","text":"","title":"Design"},{"location":"design/#first-half-provide-scenarios-for-the-development-team-to-make-the-ai","text":"Our goal is to make an AI playtest agent that could learn to play a turn-based card game and provide valuable feedback to the game designer. Valuable feedback includes: Game Balance Economy Balance Game Mechanics Game too easy/hard Dominant strategy Card Design Deck Building To deliver that feedback, the very first thing we need to do is make sure that our AI knows how to play the game, and master the game.","title":"First Half: Provide scenarios for the development team to make the AI"},{"location":"design/#the-first-deck-that-i-provided","text":"Strike+ : Deal 9 damage *4 Defend : Gain 5 Block *3 Shrug it off : Gain 8 Block. Draw 1 card. Pommel Strike+ : Deal 10 damage. Draw 2 cards Flex : Gain 2 strength, and lost it at the end of the game Thunderclap : Deal 4 damage and apply 1 vulnerable to all enemies Twin Strike+ : Deal 7 damage twice Bludgeon : Deal 32 damage This deck has a 100% win rate when a human player plays it. This means our AI should have a win rate highly close to 100%. This makes it easier for our development team to see how good our AI is. This deck is: Easy It only has 8 different cards, 1 debuff for the boss, and 1 buff for the player. It only has 13 cards, each card gets recycled very fast. Bludgeon A very useful card that dealt a significant amount of damage Flex 0 cost card that can boost up attack cards. This card should be played first when drawing it, this will be a good reference for us to see our AI\u2019s strategy. We are anticipating our AI will figure out the correct combo of playing Flex Thunderclap and then another attack card. What do we learn from this deck? Actually, this is not the first version of the deck, in the very first version, we have bludgeon+ and bash+ instead of bludgeon and thunderclap. And we had a 100% win rate. The reason we decided to change that is that the player could always win by only playing attack cards. If we use the deck to test our AI, it could have a very high win rate even if our AI is not sophisticated enough. After changing to the current deck, a random bot will not work in this situation. The player needs to manage when to play attack and when to play defense. During the human playtest result, the ending margin of player HP and boss HP are pretty close, close to zero. How does our AI perform on this deck? Our AI finally got nearly 90% of the win rate on this deck, however, it is still not willing to play flex before other attack cards. In the designer\u2019s mind, we thought that always playing flex at the beginning of the turn is an obvious move. The AI is not following that.","title":"The first deck that I provided:"},{"location":"design/#the-second-deck-that-i-provided","text":"Bash : Deal 8 damage. Apply 2 Vulnerable. Shockwave : Apply 3 Weak and Vulnerable to ALL enemies. Exhaust. Sword Boomerang+ : Deal 3 damage to a random enemy 4 times. *2 Cleave+ : Deal 11 damage to ALL enemies. *2 Iron Wave : Gain 5 Block. Deal 5 damage. *2 Feed+ : Deal 12 damage. If this kills a non-minion enemy, gain 4 permanent Max HP. Exhaust. Clothesline+ : Deal 14 damage. Apply 3 Weak. Heavy Blade+ : Deal 14 damage. Strength affects Heavy Blade 5 times. *2 Impervious : Gain 30 Block. Exhaust. Disarm : Enemy loses 2 Strength. Exhaust. Double Tap : This turn, your next Attack is played twice. Uppercut : Deal 13 damage. Apply 1 Weak. Apply 1 Vulnerable. According to our playtest, we also secured a 100% win rate on this deck. This deck is a lot harder than the first deck, it involves more exhaust cards. Exhaust card means card that only could play once in the entire boss fight. This deck is: Hard It has 13 different cards, each of them has unique usability. It has more buffs. It only has 2 to 3 defensive cards with less block value. Majority of the cards cost 2 energy. Double Tap A powerful card that empowers the next attack cards. Exhaust cards Can only play once in the entire game. It provides a deeper task to the AI to figure out which turn is the best turn to play the exhaust cards. What do we learn from this deck? When the AI could win the game, it will not try to maximize its damage in every single turn. So the difficulty of a deck is related to the performance of the AI, if the AI faces a much more difficult deck, it will try to maximize its damage. How does our AI perform on this deck? Our AI finally got 87% of the win rate on this deck, which is pretty good. The AI seems more likely to use 2 same attack cards instead of double tap and then attack card. The results are the same.","title":"The second deck that I provided:"},{"location":"generalization/","text":"Generalization","title":"Generalization"},{"location":"generalization/#generalization","text":"","title":"Generalization"},{"location":"guide/","text":"App Instructions","title":"App Instructions"},{"location":"guide/#app-instructions","text":"","title":"App Instructions"},{"location":"introduction/","text":"Introduction Video (8 minutes)","title":"Introduction"},{"location":"introduction/#introduction-video-8-minutes","text":"","title":"Introduction Video (8 minutes)"},{"location":"page1/","text":"This is page 1","title":"This is page 1"},{"location":"page1/#this-is-page-1","text":"","title":"This is page 1"},{"location":"page2/","text":"page22222 header","title":"Page2"},{"location":"page2/#page22222-header","text":"","title":"page22222 header"},{"location":"takeaways/","text":"Takeaways","title":"Takeaways"},{"location":"takeaways/#takeaways","text":"","title":"Takeaways"},{"location":"week1/","text":"Week 1 : Getting Started The objective of our project is to create an AI that can playtest card games and help balance it. We expect that the AI will identify dominant strategies to win the game, and this can lead us to making game design updates to the game. To do this, we are going to design our own card game because we want flexibility over the rules of the game. We want to test our AI with different game mechanics to see what problems (in the context of card game mechanics) it can solve easily and where it struggles. We plan to use Python to build our game kernel and have some communication with Unity for visualization of game play. For our project to work successful, we have divided it up into multiple aspects \u2013 the core game kernel, the AI, communication with Unity and game design for the card game. We need to work towards implementing each of these and ensure that they work well together. Game-AI-Input System The following is a simple representation of our system that implements the above. Here are the requirements from this system: All the gameplay logic executed in a module called\u201dgameplayKernel\u201d Other modules are only able to provide userInput and get what gameState and triggered gameEvents after this input. Exactly how game logic is executed is 100% invisible to them. All the gamedata is separated into a structure call game state. Game kernel is 100% decoupled with graphics/UI and AI training In the first week, our objective was to come up with a playable Rock-Paper-Scissor-Dragon card game and then train an AI agent to play it. RPSD is our take on the classic (and balanced) Rock-Paper-Scissor game with the exception that there is a Dragon action that defeats rock, paper and scissors but draws to another Dragon. The idea behind doing this is to prove that in the simplest of settings, the AI agent can identify the obviously broken part of the game. Unity \u2013 Python Connection Research on the ways to achieve this: To have a python interpreter in .NET environment (https://ironpython.net/) . The cons is this is not stable, and will have some trouble when using external python packages like numpy. Use command line to execute the python program, and redirect the standard input/output from cmd to C#/Unity environment. This is doable, but using standard input/output to communicate is inconvenience. And this need player to install the python environment Python programs run in another process, and Unity in another process. Use socket to transfer the information between to language. This is what we finally chose, but it still needs more work. We need to think about how to call a function and share object instances. AI Agent Since the AI problem is so simple, we implemented followed a simple tabular reinforcement learning approach. To elaborate, we maintain a table of the expected reward from taking each of the four actions (rock, paper, scissor or dragon). We update these expected reward values based on the rewards from each game. The agent uses an epsilon-greedy approach with a constant epsilon value of 0.1. Since the dragon will naturally has the highest chance of winning any game, over a period of time the expected reward for a dragon is the highest. Here are some charts of the training results. Each plot shows the number of times the AI agent picked each action. We see that after 100,000 steps, the AI agent predominantly picks the dragon action. The minority of actions that are not dragon can be attributed to the epsilon probability value. Although, this worked, we are well aware that this problem is trivial compared to building an AI to play a complex card game. Since the action and state space can be very large, a tabular reinforcement learning approach can no longer work. In this situation, we need to use a neural network to estimate expected reward. The input layer can be a vector of integer values that represent the current state space. The output layer is more tricky because it involves a fairly complex action selection. Game Design Last but not the least, we arrive at the game design component of our project. We plan to have a game that starts with a simple rules and few mechanics but eventually evolves into something more complex. This can help with us progressively increase the reinforcement learning model complexity. The first version of the game only involves two systems: Hero system Card system The hero system consists of two set of actions to choose from. Player has to decide the positioning of each hero in each round, because normally a hero can only attack the enemy that is in front of it. Additionally, each hero will have two extra skills that require a particular resource to unlock, which is the second set of actions that needs decision making. The card system also requires players to make decisions between short long term rewards. The player may choose to deal maximum damage each turn, or choose to gain resources to level up and fight back. Ideally, we want a variety of different strategies to be viable The game, of course, requires large amounts of balancing. For example, the HP and attack damage of each hero, the amount of resources that are required to level up a skill, and the drawing probabilities of each card are all crucial to this game being balanced. This is where we hope the AI can help us out. In conclusion, we believe we have had a strong start to the project. Our objectives that we need to achieve are clear. We want to explore relatively unexplored territory that is technically very challenging. All we know for certain is that we are excited!","title":"Week 1 : Getting Started"},{"location":"week1/#week-1-getting-started","text":"The objective of our project is to create an AI that can playtest card games and help balance it. We expect that the AI will identify dominant strategies to win the game, and this can lead us to making game design updates to the game. To do this, we are going to design our own card game because we want flexibility over the rules of the game. We want to test our AI with different game mechanics to see what problems (in the context of card game mechanics) it can solve easily and where it struggles. We plan to use Python to build our game kernel and have some communication with Unity for visualization of game play. For our project to work successful, we have divided it up into multiple aspects \u2013 the core game kernel, the AI, communication with Unity and game design for the card game. We need to work towards implementing each of these and ensure that they work well together.","title":"Week 1 : Getting Started"},{"location":"week1/#game-ai-input-system","text":"The following is a simple representation of our system that implements the above. Here are the requirements from this system: All the gameplay logic executed in a module called\u201dgameplayKernel\u201d Other modules are only able to provide userInput and get what gameState and triggered gameEvents after this input. Exactly how game logic is executed is 100% invisible to them. All the gamedata is separated into a structure call game state. Game kernel is 100% decoupled with graphics/UI and AI training In the first week, our objective was to come up with a playable Rock-Paper-Scissor-Dragon card game and then train an AI agent to play it. RPSD is our take on the classic (and balanced) Rock-Paper-Scissor game with the exception that there is a Dragon action that defeats rock, paper and scissors but draws to another Dragon. The idea behind doing this is to prove that in the simplest of settings, the AI agent can identify the obviously broken part of the game.","title":"Game-AI-Input System"},{"location":"week1/#unity-python-connection","text":"Research on the ways to achieve this: To have a python interpreter in .NET environment (https://ironpython.net/) . The cons is this is not stable, and will have some trouble when using external python packages like numpy. Use command line to execute the python program, and redirect the standard input/output from cmd to C#/Unity environment. This is doable, but using standard input/output to communicate is inconvenience. And this need player to install the python environment Python programs run in another process, and Unity in another process. Use socket to transfer the information between to language. This is what we finally chose, but it still needs more work. We need to think about how to call a function and share object instances.","title":"Unity \u2013 Python Connection"},{"location":"week1/#ai-agent","text":"Since the AI problem is so simple, we implemented followed a simple tabular reinforcement learning approach. To elaborate, we maintain a table of the expected reward from taking each of the four actions (rock, paper, scissor or dragon). We update these expected reward values based on the rewards from each game. The agent uses an epsilon-greedy approach with a constant epsilon value of 0.1. Since the dragon will naturally has the highest chance of winning any game, over a period of time the expected reward for a dragon is the highest. Here are some charts of the training results. Each plot shows the number of times the AI agent picked each action. We see that after 100,000 steps, the AI agent predominantly picks the dragon action. The minority of actions that are not dragon can be attributed to the epsilon probability value. Although, this worked, we are well aware that this problem is trivial compared to building an AI to play a complex card game. Since the action and state space can be very large, a tabular reinforcement learning approach can no longer work. In this situation, we need to use a neural network to estimate expected reward. The input layer can be a vector of integer values that represent the current state space. The output layer is more tricky because it involves a fairly complex action selection.","title":"AI Agent"},{"location":"week1/#game-design","text":"Last but not the least, we arrive at the game design component of our project. We plan to have a game that starts with a simple rules and few mechanics but eventually evolves into something more complex. This can help with us progressively increase the reinforcement learning model complexity. The first version of the game only involves two systems: Hero system Card system The hero system consists of two set of actions to choose from. Player has to decide the positioning of each hero in each round, because normally a hero can only attack the enemy that is in front of it. Additionally, each hero will have two extra skills that require a particular resource to unlock, which is the second set of actions that needs decision making. The card system also requires players to make decisions between short long term rewards. The player may choose to deal maximum damage each turn, or choose to gain resources to level up and fight back. Ideally, we want a variety of different strategies to be viable The game, of course, requires large amounts of balancing. For example, the HP and attack damage of each hero, the amount of resources that are required to level up a skill, and the drawing probabilities of each card are all crucial to this game being balanced. This is where we hope the AI can help us out. In conclusion, we believe we have had a strong start to the project. Our objectives that we need to achieve are clear. We want to explore relatively unexplored territory that is technically very challenging. All we know for certain is that we are excited!","title":"Game Design"},{"location":"week10/","text":"","title":"Week10"},{"location":"week11/","text":"","title":"Week11"},{"location":"week12/","text":"","title":"Week12"},{"location":"week13/","text":"","title":"Week13"},{"location":"week14/","text":"","title":"Week14"},{"location":"week15/","text":"","title":"Week15"},{"location":"week2/","text":"Week 2 : First Version Our goal for the week was to start building the first version of our card game. The components of our system architecture include the game kernel, the AI agent and visualization of the game states in Unity. The other important aspect is the design of the card game which is really what everything is for. Card Game Design As discussed in the last week\u2019s post, our strategy is to start with a simple card game and progressively introduce more complexity. This week, we came up with the first iteration of our game and here are the rules. Each player will have the same health amount and attack damage. Only two kinds of cards inside the deck: Heal and Damage. First round each player will have 5 cards and will draw 2 cards each round from the second round. Players will take turns, and they will use all of their cards in hand. Game Kernel The following is a list of files that we have implemented and what each of them does: GameSimulator.py: Allows us to simulate the game multiple times and view results. GameplayKernel.py: Kernel class that instantiates a game state object to \u2018play\u2019 the card game. commonDef.py: Defines game state related classes in order to have a concise interface for Unity and AI agent training. AutoPlayerDef.py: A bot that randomly picks one card from its hand to play out in each round. constantDef.py: Defines constant values used in our project. AI Agent Since we cannot use a tabular approach for our game (as the state-action space is very large), we need to use a neural network. The input layer to the neural network will pass in state defining variable values. We still working on a comprehensive list of such variables. The output layer will then give us a probability distribution over the action space. Using this, we can sample from an action from it or simply take the action that has the highest probability (we plan to try both). The design is of the Policy Gradient RL method. The algorithm that we will begin with is the Advantage Actor Critic. The reason for beginning with policy based methods (over value based methods) is that they perform better in stochastic environments. This applies to our project, because the same actions can result in a different future states based on the moves made by the opponent. During the course of our project, it is likely that we shall try several different approaches to train our AI. We are open to trying value based methods if the Advantage Actor Critic algorithm does not perform well in our setting. Another important aspect to consider is the number of states that we pass into the input layer during training. Since playing a particular card could lead to victory multiple turns later, the reward received after taking a particular action must include discounted future rewards as well. This means that we follow a N-step reward where N is the number of future steps to consider for the reward. Visualization and Input Handling in Unity There are several parts to the Unity system that we are building alongside with our Python game. Networking System For playtesting reasons, we want to allow people to play this game remotely. To that end, we are building a networked Unity system that can allow people to provide inputs remotely through the client. We are using Photon to do this. The reasons for using Photon: Provides free server usage within a limit. Provides easy-to-use API for building room/lobby-based game service. Great support and tutorial resources in Unity. Using Photon, we have built a basic matching system that works for us. It currently includes functionality for: Connecting players to the service. Manage the connection and disconnection. Logic of \u2018Ready\u2019, \u2018Start Game\u2019, and player chat. Below are some screenshots of how this looks currently. Rules of communication between Python and Unity (C#) We have discussed the rules of how AI, Unity logic, python gameplayer will communicate (to ensure less work when we connect everything). Definition and format of important classes such as gamestate/user input is predefined and stored in a python file (commonDef.py). C#/Python communication: Only C# accesses Python, not the other way around C# can only do the following: Call functions, share data structures, and get the snapshot of object instances in python. C# and Python will share the definition of classes which are commonly referenced by both. Const values and settings will be stored in separate files(XML, JSON, etc.) and will be dynamically loaded when required. C# Coding Standard We added a coding style guide of Unity/C# in our Github repository\u2019s readme file, including rules for class layout, nomenclature, declaration and brace style.","title":"Week 2 : First Version"},{"location":"week2/#week-2-first-version","text":"Our goal for the week was to start building the first version of our card game. The components of our system architecture include the game kernel, the AI agent and visualization of the game states in Unity. The other important aspect is the design of the card game which is really what everything is for.","title":"Week 2 : First Version"},{"location":"week2/#card-game-design","text":"As discussed in the last week\u2019s post, our strategy is to start with a simple card game and progressively introduce more complexity. This week, we came up with the first iteration of our game and here are the rules. Each player will have the same health amount and attack damage. Only two kinds of cards inside the deck: Heal and Damage. First round each player will have 5 cards and will draw 2 cards each round from the second round. Players will take turns, and they will use all of their cards in hand.","title":"Card Game Design"},{"location":"week2/#game-kernel","text":"The following is a list of files that we have implemented and what each of them does: GameSimulator.py: Allows us to simulate the game multiple times and view results. GameplayKernel.py: Kernel class that instantiates a game state object to \u2018play\u2019 the card game. commonDef.py: Defines game state related classes in order to have a concise interface for Unity and AI agent training. AutoPlayerDef.py: A bot that randomly picks one card from its hand to play out in each round. constantDef.py: Defines constant values used in our project.","title":"Game Kernel"},{"location":"week2/#ai-agent","text":"Since we cannot use a tabular approach for our game (as the state-action space is very large), we need to use a neural network. The input layer to the neural network will pass in state defining variable values. We still working on a comprehensive list of such variables. The output layer will then give us a probability distribution over the action space. Using this, we can sample from an action from it or simply take the action that has the highest probability (we plan to try both). The design is of the Policy Gradient RL method. The algorithm that we will begin with is the Advantage Actor Critic. The reason for beginning with policy based methods (over value based methods) is that they perform better in stochastic environments. This applies to our project, because the same actions can result in a different future states based on the moves made by the opponent. During the course of our project, it is likely that we shall try several different approaches to train our AI. We are open to trying value based methods if the Advantage Actor Critic algorithm does not perform well in our setting. Another important aspect to consider is the number of states that we pass into the input layer during training. Since playing a particular card could lead to victory multiple turns later, the reward received after taking a particular action must include discounted future rewards as well. This means that we follow a N-step reward where N is the number of future steps to consider for the reward.","title":"AI Agent"},{"location":"week2/#visualization-and-input-handling-in-unity","text":"There are several parts to the Unity system that we are building alongside with our Python game.","title":"Visualization and Input Handling in Unity"},{"location":"week2/#networking-system","text":"For playtesting reasons, we want to allow people to play this game remotely. To that end, we are building a networked Unity system that can allow people to provide inputs remotely through the client. We are using Photon to do this. The reasons for using Photon: Provides free server usage within a limit. Provides easy-to-use API for building room/lobby-based game service. Great support and tutorial resources in Unity. Using Photon, we have built a basic matching system that works for us. It currently includes functionality for: Connecting players to the service. Manage the connection and disconnection. Logic of \u2018Ready\u2019, \u2018Start Game\u2019, and player chat. Below are some screenshots of how this looks currently.","title":"Networking System"},{"location":"week2/#rules-of-communication-between-python-and-unity-c","text":"We have discussed the rules of how AI, Unity logic, python gameplayer will communicate (to ensure less work when we connect everything). Definition and format of important classes such as gamestate/user input is predefined and stored in a python file (commonDef.py). C#/Python communication: Only C# accesses Python, not the other way around C# can only do the following: Call functions, share data structures, and get the snapshot of object instances in python. C# and Python will share the definition of classes which are commonly referenced by both. Const values and settings will be stored in separate files(XML, JSON, etc.) and will be dynamically loaded when required.","title":"Rules of communication between Python and Unity (C#)"},{"location":"week2/#c-coding-standard","text":"We added a coding style guide of Unity/C# in our Github repository\u2019s readme file, including rules for class layout, nomenclature, declaration and brace style.","title":"C# Coding Standard"},{"location":"week3/","text":"Week 3 : The Card Game The biggest highlight this was the pivot. Instead of designing our own game, we decided to go with the popular card game \u2018Slay the Spire\u2019. There were several reasons for doing this. During a recently held Brainstorming Workshop that involved a lot of second year students, we got some feedback that resembled a lot of the same things we had been hearing from our faculty instructors and others who we had described our project to. Since we were implementing the AI and designing the game at the same time, it would have been easy for us to change the game\u2019s design in order to make it more suitable for AI training. This has never been the purpose of our project. We dont want to be changing the game in order to suit the AI. We want the game and its design to drive the AI instead of the other way round. This is because we want to work towards something that can be extended to other games and other settings. And although we are not looking towards developing an AI that can play multiple card games (this is an extremely difficult task), we need to be able to develop AI for a game not designed by us to convince anyone that our work has merit. The Card Game \u2013 Slay the Spire The game that we chose is Slay the Spire . There are several reasons for choosing this game: Simple and Well Designed : Slay the Spire is a well designed game that is a lot of fun to play. The buff system is uniform and consistent which makes it a good setting for AI training. There arent a lot of programming exceptions when it comes to programming which makes the implementation easier. PvE : The game is not player versus player which makes the gameplay more deterministic. With the game concept we had earlier, we were heading towards adversarial AI agents that compete with each other to win. Instead, here we have the AI agent playing against a scripted boss. This makes the training process less complex because the environment is relatively much less stochastic. Data Driven Design : Each card is basically a data structure with specific values for damage, block and buffs. Thus each card can be stored as its own JSON object and it is simple to modify. It also makes it easier for us to add new cards. That being said, we are not looking to build an AI system for the entire game. We are only looking at boss fights with a predetermined deck of cards. As a result, we are only looking to train the AI to play out boss fights. If the AI can learn how to play the boss fight, we can get an understanding of how easy or difficult it is to beat the boss when the damage, block or buff values are altered. Game Jam \u2013 Implementation After deciding that we wanted a already popular card game and then choosing \u2018Slay the Spire\u2019, it was time to move towards the implementation. We had already worked towards the implementation of the previous game and as a result we didnt like the fact that we were back to square one. To overcome this, we decided to do a game jam (Wednesday to Friday) where all three programmers drop everything else and work together to quickly implement a playable version of Slay the Spire. The following are some of the requirements we came up with for this rapid implementation to direct us: Friendly for AI to play, and also can by played by humans using the terminal Clear protocol for the deck and cards for future extensibility (ties into the Data Driven Design which we wanted to preserve) Flexible and agile. It is a rapidly made prototype, but the code will serve as the foundation for what we do in the future Calling this our own little game jam was a great idea. We quickly divided up the work and started while staying connected on Discord to answer each other\u2019s questions. After three long days, we had a terminal-playable prototype of the card game on our hands. It consisted of one boss combat ( The Guardian ) and twelve cards for the player to choose from. The cards that we implemented are as follows: Anger Defend Shrug It Off Pommel Strike Sword Boomerang Body Slam Iron Wave Heavy Blade Flex Double Tap Disarm Clothesline Currently this game is human playable in the terminal. This will change in the future and the game will be playable through a UI. However, for now the play experience is a little more tedious with the player having to choose every card to play one by one. The following is a screenshot of how that looks. Here is a list of different game systems that have been implemented so far: GameManager for managing the game flow, providing API for AI and input management Deck management, which provides the ability import cards and deck information from JSON files Behavior system for entities such as player and enemy Implementation of a decision tree for the boss, which has different modes and various tactics. The next steps include getting back to developing an AI that can play this game. We are simultaneously getting ready for quarters next which will give us a great chance to get feedback about our plan from ETC faculty.","title":"Week 3 : The Card Game"},{"location":"week3/#week-3-the-card-game","text":"The biggest highlight this was the pivot. Instead of designing our own game, we decided to go with the popular card game \u2018Slay the Spire\u2019. There were several reasons for doing this. During a recently held Brainstorming Workshop that involved a lot of second year students, we got some feedback that resembled a lot of the same things we had been hearing from our faculty instructors and others who we had described our project to. Since we were implementing the AI and designing the game at the same time, it would have been easy for us to change the game\u2019s design in order to make it more suitable for AI training. This has never been the purpose of our project. We dont want to be changing the game in order to suit the AI. We want the game and its design to drive the AI instead of the other way round. This is because we want to work towards something that can be extended to other games and other settings. And although we are not looking towards developing an AI that can play multiple card games (this is an extremely difficult task), we need to be able to develop AI for a game not designed by us to convince anyone that our work has merit.","title":"Week 3 : The Card Game"},{"location":"week3/#the-card-game-slay-the-spire","text":"The game that we chose is Slay the Spire . There are several reasons for choosing this game: Simple and Well Designed : Slay the Spire is a well designed game that is a lot of fun to play. The buff system is uniform and consistent which makes it a good setting for AI training. There arent a lot of programming exceptions when it comes to programming which makes the implementation easier. PvE : The game is not player versus player which makes the gameplay more deterministic. With the game concept we had earlier, we were heading towards adversarial AI agents that compete with each other to win. Instead, here we have the AI agent playing against a scripted boss. This makes the training process less complex because the environment is relatively much less stochastic. Data Driven Design : Each card is basically a data structure with specific values for damage, block and buffs. Thus each card can be stored as its own JSON object and it is simple to modify. It also makes it easier for us to add new cards. That being said, we are not looking to build an AI system for the entire game. We are only looking at boss fights with a predetermined deck of cards. As a result, we are only looking to train the AI to play out boss fights. If the AI can learn how to play the boss fight, we can get an understanding of how easy or difficult it is to beat the boss when the damage, block or buff values are altered.","title":"The Card Game \u2013 Slay the Spire"},{"location":"week3/#game-jam-implementation","text":"After deciding that we wanted a already popular card game and then choosing \u2018Slay the Spire\u2019, it was time to move towards the implementation. We had already worked towards the implementation of the previous game and as a result we didnt like the fact that we were back to square one. To overcome this, we decided to do a game jam (Wednesday to Friday) where all three programmers drop everything else and work together to quickly implement a playable version of Slay the Spire. The following are some of the requirements we came up with for this rapid implementation to direct us: Friendly for AI to play, and also can by played by humans using the terminal Clear protocol for the deck and cards for future extensibility (ties into the Data Driven Design which we wanted to preserve) Flexible and agile. It is a rapidly made prototype, but the code will serve as the foundation for what we do in the future Calling this our own little game jam was a great idea. We quickly divided up the work and started while staying connected on Discord to answer each other\u2019s questions. After three long days, we had a terminal-playable prototype of the card game on our hands. It consisted of one boss combat ( The Guardian ) and twelve cards for the player to choose from. The cards that we implemented are as follows: Anger Defend Shrug It Off Pommel Strike Sword Boomerang Body Slam Iron Wave Heavy Blade Flex Double Tap Disarm Clothesline Currently this game is human playable in the terminal. This will change in the future and the game will be playable through a UI. However, for now the play experience is a little more tedious with the player having to choose every card to play one by one. The following is a screenshot of how that looks. Here is a list of different game systems that have been implemented so far: GameManager for managing the game flow, providing API for AI and input management Deck management, which provides the ability import cards and deck information from JSON files Behavior system for entities such as player and enemy Implementation of a decision tree for the boss, which has different modes and various tactics. The next steps include getting back to developing an AI that can play this game. We are simultaneously getting ready for quarters next which will give us a great chance to get feedback about our plan from ETC faculty.","title":"Game Jam \u2013 Implementation"},{"location":"week4/","text":"Week 4 : Dawn Of The AI This week involved many things. We had a chance to interact with many ETC faculty during the 1/4 walkarounds. This was a great chance for us to showcase what we had accomplished to far and talk about our direction. We ran AI training multiple times with different model structures and hyperparameter values. Unfortunately, we could never achieve a win rate of more than 15.7% which means that we still have a lot of work to do towards the machine learning aspect of the project. Meanwhile, we also came up with a Unity frontend system for visualizing the gameplay and created a Django (python) website on localserver that gives designers a simple GUI to edit card values and even create new ones. Feedback from Quarter Walkarounds Here\u2019s a list of some of the most important feedback we received: We need to come up with one or two metrics that we \u2018target\u2019. By targeting a metric, we want to measure the impact of making game balance updates on these metrics. For example, one of the metrics that we are leaning towards is win rate. By focusing on win rate, we can put game balance changes in perspective to judge whats good and whats not. We need to reach out people in the reinforcement learning space who can help us out with the AI part. Since this space is technically challenging and it is is still quite unexplored, it would be a good idea to get in touch with someone more experienced in the space. We need to create an organized system that can help game designers interact with the AI. This can be to help with inference from general statistics by creating data visualizations or even an interface to train the AI after making game design updates. We need to write a paper as our final deliverable. This makes sense because what we are doing is highly exploratory. A good to extract value from the work that we have done is to document it all for people who may want to work in the same space after us. AI Training Experiments This week involved a lot of AI training experiments. In all honesty, none of our experiments were successful. The highest win rate that we ever got was 15.7% and that is not very good. However, it is still a little better than a random bot. There were two models that we implemented this week: Model 1 : Single Model With All Input Data This is a single model that takes in all of the state input at the same time. This results in 98 input neurons that look like the following: The output consists of estimated Q-values for each card. The neural network is setup to estimate the expected reward values from playing each card given a particular state. The AI agent will then go ahead and play the playable card with the highest Q-value. This does not always mean that the card with highest Q-value gets played since it might not be possible to play that card (player energy, card not in hand, etc). There were several issues with this model that we had to iron out as we ran training. For one, the estimated Q-values were getting very large and would eventually resulted in a Nan error. This was rectified by changing the activation function of the middle layers to sigmoid instead of relu. We also tried regularization as a way to handle this but that resulted in the estimated Q-values being too small. All in all, we got the model to work but it did not show any improvement in the average reward over the duration of the training. Perhaps, it is difficult for the AI to infer insights from the data because too much of it is being presented at once inconsistently. Model 2 : Multiple Small Models Each Predicting Independently The other model we implemented involved getting rid of a single big model but instead making multiple small models. For the sake of experimentation, we created three smaller models as follows: Buff Model \u2013 Consists of 7 input neurons, each indicating whether a certain buff is present on the player (or boss). Cards Model \u2013 Consists of 13 input neurons indicating which cards are in the players hand. One additional neuron to indicate player\u2019s energy level. Boss Intent Model \u2013 Consists of 7 inputs neurons, indicating what is boss\u2019s intent. Out of the 98 values that indicate the game\u2019s current state in model 1, here we are only taking 7 + 13 + 7 of them. By filtering out some of the information, we are losing out out on the AI\u2019s knowledge of the state space but at the same time we want to try this out to see if the AI does any better. By taking a weighted average of the independent Q-values predicted by these three smaller models, we were able to get a win rate of 15.7% which is higher than the random bot. This is good news, because we know that we are doing in the right direction. However, with that being said, the performance is still quite bad. We are now looking to implementing a more complex and fine-tuned reward function that could potentially help with improvement of training. If that too does not prove to be helpful, we shall look towards policy gradient algorithms to try and solve this problem with a fresh approach. Unity Visualization We made some progress on our quest to create a Unity visualization of the game. In the last week (Week 3) we had implemented a python version of the game \u2018Slay the Spire\u2019 which involved a single boss fight against the level 1 boss \u2018The Guardian\u2019. For starters, we worked towards implementing a UI for playing the game which looks like the below. The following are some key features of the Unity system: Decoupled Front End : Front-end includes all animations, UI, and graphics, but does not have any control over the gameplay logic. Data Driven Rendering : Rendering of the game is based on data, just like browsers render HTML. So when we change game logic in python, the rendering part would change according to the data sent back from python. This ensures that we dont need to modify the python code too much. Art Resources Hot Update : Art-side resources shouldn\u2019t be embedded in the application. All of them are configurable and can be hot updated. Art assets can also be provided as tools (for the game designer) and results can be immediately seen without restarting the application. Playback System and Debugger : Support for a playback system based on log data. This is to see how AI plays the game by visualizing its moves. The implementation of the Unity Visualization system follows a front-end/back-end architecture. This is largely inspired from the modern web stack: HTML/Browser/CSS/JS because we have a similar situation. Instead of a game application, Unity is simply a renderer along with some input management. It renders the information from the python module, and gathers user input to send back to python. It is very similar to the relationship between browser and server. The following is a diagram of how this architecture looks: Web GUI for Card Modifications An important piece of our project is to make our system more friendly for game designers. To that end, we began work towards a web GUI for editing the json card files. The idea behind this system is to let the users modify existing cards or create new cards. This system uses a Django backend that is hosted on localserver for editing the card files locally. The following is a screenshot of how this looks right now: The fields in the image are from the card json files. These are all values that would need to be edited by opening up the json file. Instead, this system can also be used to make similar changes. In conclusion, this week involved progress on multiple fronts. However, the biggest concern right now is that the AI is not performing well. In the coming week, more of our efforts will likely be to push towards success in this area.","title":"Week 4 : Dawn Of The AI"},{"location":"week4/#week-4-dawn-of-the-ai","text":"This week involved many things. We had a chance to interact with many ETC faculty during the 1/4 walkarounds. This was a great chance for us to showcase what we had accomplished to far and talk about our direction. We ran AI training multiple times with different model structures and hyperparameter values. Unfortunately, we could never achieve a win rate of more than 15.7% which means that we still have a lot of work to do towards the machine learning aspect of the project. Meanwhile, we also came up with a Unity frontend system for visualizing the gameplay and created a Django (python) website on localserver that gives designers a simple GUI to edit card values and even create new ones.","title":"Week 4 : Dawn Of The AI"},{"location":"week4/#feedback-from-quarter-walkarounds","text":"Here\u2019s a list of some of the most important feedback we received: We need to come up with one or two metrics that we \u2018target\u2019. By targeting a metric, we want to measure the impact of making game balance updates on these metrics. For example, one of the metrics that we are leaning towards is win rate. By focusing on win rate, we can put game balance changes in perspective to judge whats good and whats not. We need to reach out people in the reinforcement learning space who can help us out with the AI part. Since this space is technically challenging and it is is still quite unexplored, it would be a good idea to get in touch with someone more experienced in the space. We need to create an organized system that can help game designers interact with the AI. This can be to help with inference from general statistics by creating data visualizations or even an interface to train the AI after making game design updates. We need to write a paper as our final deliverable. This makes sense because what we are doing is highly exploratory. A good to extract value from the work that we have done is to document it all for people who may want to work in the same space after us.","title":"Feedback from Quarter Walkarounds"},{"location":"week4/#ai-training-experiments","text":"This week involved a lot of AI training experiments. In all honesty, none of our experiments were successful. The highest win rate that we ever got was 15.7% and that is not very good. However, it is still a little better than a random bot. There were two models that we implemented this week:","title":"AI Training Experiments"},{"location":"week4/#model-1-single-model-with-all-input-data","text":"This is a single model that takes in all of the state input at the same time. This results in 98 input neurons that look like the following: The output consists of estimated Q-values for each card. The neural network is setup to estimate the expected reward values from playing each card given a particular state. The AI agent will then go ahead and play the playable card with the highest Q-value. This does not always mean that the card with highest Q-value gets played since it might not be possible to play that card (player energy, card not in hand, etc). There were several issues with this model that we had to iron out as we ran training. For one, the estimated Q-values were getting very large and would eventually resulted in a Nan error. This was rectified by changing the activation function of the middle layers to sigmoid instead of relu. We also tried regularization as a way to handle this but that resulted in the estimated Q-values being too small. All in all, we got the model to work but it did not show any improvement in the average reward over the duration of the training. Perhaps, it is difficult for the AI to infer insights from the data because too much of it is being presented at once inconsistently.","title":"Model 1 : Single Model With All Input Data"},{"location":"week4/#model-2-multiple-small-models-each-predicting-independently","text":"The other model we implemented involved getting rid of a single big model but instead making multiple small models. For the sake of experimentation, we created three smaller models as follows: Buff Model \u2013 Consists of 7 input neurons, each indicating whether a certain buff is present on the player (or boss). Cards Model \u2013 Consists of 13 input neurons indicating which cards are in the players hand. One additional neuron to indicate player\u2019s energy level. Boss Intent Model \u2013 Consists of 7 inputs neurons, indicating what is boss\u2019s intent. Out of the 98 values that indicate the game\u2019s current state in model 1, here we are only taking 7 + 13 + 7 of them. By filtering out some of the information, we are losing out out on the AI\u2019s knowledge of the state space but at the same time we want to try this out to see if the AI does any better. By taking a weighted average of the independent Q-values predicted by these three smaller models, we were able to get a win rate of 15.7% which is higher than the random bot. This is good news, because we know that we are doing in the right direction. However, with that being said, the performance is still quite bad. We are now looking to implementing a more complex and fine-tuned reward function that could potentially help with improvement of training. If that too does not prove to be helpful, we shall look towards policy gradient algorithms to try and solve this problem with a fresh approach.","title":"Model 2 : Multiple Small Models Each Predicting Independently"},{"location":"week4/#unity-visualization","text":"We made some progress on our quest to create a Unity visualization of the game. In the last week (Week 3) we had implemented a python version of the game \u2018Slay the Spire\u2019 which involved a single boss fight against the level 1 boss \u2018The Guardian\u2019. For starters, we worked towards implementing a UI for playing the game which looks like the below. The following are some key features of the Unity system: Decoupled Front End : Front-end includes all animations, UI, and graphics, but does not have any control over the gameplay logic. Data Driven Rendering : Rendering of the game is based on data, just like browsers render HTML. So when we change game logic in python, the rendering part would change according to the data sent back from python. This ensures that we dont need to modify the python code too much. Art Resources Hot Update : Art-side resources shouldn\u2019t be embedded in the application. All of them are configurable and can be hot updated. Art assets can also be provided as tools (for the game designer) and results can be immediately seen without restarting the application. Playback System and Debugger : Support for a playback system based on log data. This is to see how AI plays the game by visualizing its moves. The implementation of the Unity Visualization system follows a front-end/back-end architecture. This is largely inspired from the modern web stack: HTML/Browser/CSS/JS because we have a similar situation. Instead of a game application, Unity is simply a renderer along with some input management. It renders the information from the python module, and gathers user input to send back to python. It is very similar to the relationship between browser and server. The following is a diagram of how this architecture looks:","title":"Unity Visualization"},{"location":"week4/#web-gui-for-card-modifications","text":"An important piece of our project is to make our system more friendly for game designers. To that end, we began work towards a web GUI for editing the json card files. The idea behind this system is to let the users modify existing cards or create new cards. This system uses a Django backend that is hosted on localserver for editing the card files locally. The following is a screenshot of how this looks right now: The fields in the image are from the card json files. These are all values that would need to be edited by opening up the json file. Instead, this system can also be used to make similar changes. In conclusion, this week involved progress on multiple fronts. However, the biggest concern right now is that the AI is not performing well. In the coming week, more of our efforts will likely be to push towards success in this area.","title":"Web GUI for Card Modifications"},{"location":"week5/","text":"","title":"Week5"},{"location":"week6/","text":"","title":"Week6"},{"location":"week7/","text":"","title":"Week7"},{"location":"week8/","text":"","title":"Week8"},{"location":"week9/","text":"","title":"Week9"},{"location":"game/0-structure/","text":"Overview Topics Architecture Unity Player GUI Build of Multiple Frameworks Data Visualization Summary","title":"Overview"},{"location":"game/0-structure/#overview","text":"","title":"Overview"},{"location":"game/0-structure/#topics","text":"","title":"Topics"},{"location":"game/0-structure/#architecture","text":"","title":"Architecture"},{"location":"game/0-structure/#unity-player-gui","text":"","title":"Unity Player GUI"},{"location":"game/0-structure/#build-of-multiple-frameworks","text":"","title":"Build of Multiple Frameworks"},{"location":"game/0-structure/#data-visualization","text":"","title":"Data Visualization"},{"location":"game/0-structure/#summary","text":"","title":"Summary"},{"location":"game/Architecture/","text":"Brief Introduction To Architecture The Requirements The demo we present is how we image game development with AI looks like. It is also a complex software with many subsystems. As an software, it need: Player can play the game AI can play the game Designer can change the game behaviour Automate playtest with AI Visualize the data of the playtest The Architecture Frontend&Backend We divide our architecture into frontend and backend. The backend includes the core of our techique: run the gameplay and train an AI on it. The frontend is all about present the results of backend to user: player GUI present the gameplay, data visualization present the playtesting data and designer GUI present everything desginers can operate. Six Modules Database The word 'database' is not the database in web such as MySQL, its more like manager of data and records, including AI and gameplay. It's important to seperate data and the logic (gameplay logic) operating those data. Because: 1. We have multiple languages and platforms, we need a persistence layer in this archtecture 2. Much easier to build a tool for designer to configure the game. Gameplay logic We implement the gameplay in python, not C# in Unity. Because we use tensorflow to develop our AI algorithm, this is the better solution. AI Our AI module with APIs from gameplay logic to play and game and train an AI for it. It also provides APIs for Designer GUI, so designer can train AI by just clicking a button, PlayerGUI We seperate logics and graphics of a game. The logic is in python, and graphics is in this part. We use Untiy and because we implement our gameplay in python, this is hard than normal game development in Unity. Data Visualization This module visualize the data from automate playtesting. We find the d3.js this libarary. So we can render different kinds of data with large scale easily. Designer GUI This part is the core of the frontend. It acts like a glue, combine all other modules into a single app, providing GUI for designers.","title":"Architecture"},{"location":"game/Architecture/#brief-introduction-to-architecture","text":"","title":"Brief Introduction To Architecture"},{"location":"game/Architecture/#the-requirements","text":"The demo we present is how we image game development with AI looks like. It is also a complex software with many subsystems. As an software, it need: Player can play the game AI can play the game Designer can change the game behaviour Automate playtest with AI Visualize the data of the playtest","title":"The Requirements"},{"location":"game/Architecture/#the-architecture","text":"","title":"The Architecture"},{"location":"game/Architecture/#frontendbackend","text":"We divide our architecture into frontend and backend. The backend includes the core of our techique: run the gameplay and train an AI on it. The frontend is all about present the results of backend to user: player GUI present the gameplay, data visualization present the playtesting data and designer GUI present everything desginers can operate.","title":"Frontend&amp;Backend"},{"location":"game/Architecture/#six-modules","text":"","title":"Six Modules"},{"location":"game/Architecture/#database","text":"The word 'database' is not the database in web such as MySQL, its more like manager of data and records, including AI and gameplay. It's important to seperate data and the logic (gameplay logic) operating those data. Because: 1. We have multiple languages and platforms, we need a persistence layer in this archtecture 2. Much easier to build a tool for designer to configure the game.","title":"Database"},{"location":"game/Architecture/#gameplay-logic","text":"We implement the gameplay in python, not C# in Unity. Because we use tensorflow to develop our AI algorithm, this is the better solution.","title":"Gameplay logic"},{"location":"game/Architecture/#ai","text":"Our AI module with APIs from gameplay logic to play and game and train an AI for it. It also provides APIs for Designer GUI, so designer can train AI by just clicking a button,","title":"AI"},{"location":"game/Architecture/#playergui","text":"We seperate logics and graphics of a game. The logic is in python, and graphics is in this part. We use Untiy and because we implement our gameplay in python, this is hard than normal game development in Unity.","title":"PlayerGUI"},{"location":"game/Architecture/#data-visualization","text":"This module visualize the data from automate playtesting. We find the d3.js this libarary. So we can render different kinds of data with large scale easily.","title":"Data Visualization"},{"location":"game/Architecture/#designer-gui","text":"This part is the core of the frontend. It acts like a glue, combine all other modules into a single app, providing GUI for designers.","title":"Designer GUI"},{"location":"game/Build/","text":"Build of Multiple Frameworks We successfully packed everything, including unity, python, tensorflow, electron into one executable. So we can distribute our application easily to playtesters. Main Components of Build When we work on unity, unity helps to build everything inside unity. When working on an electron, we use electron-forge to build everything in the electron. However, our application uses both unity,electron and python. And there are no official tools to build them together. Electron native build : We use electron-forge to build resources managed by electrons. The main difference between normal electron build and ours is that there are many resources not managed by electrons, such as unity codes and python codes. Unity executables : There are two unity executables. One is a GUI for playing the game, another is the record playback app. In an ideal situation, these 2 should be combined into one app. Since unity build is very small, build twice is acceptable in size. Python build : We discussed how to build python into unity in previous blogs(Week6). We analyze pros and cons on different approaches. We still use \u201cpython interpreter + source codes\u201d for the same reason Database These are all static files. Just copy it into the right directory. Challenges and Solutions Build Python Environment Even we built our unity app by using \u201cpython interpreter + source codes\u201d for the source codes. We also need to consider the python environment. Provide installer in electron app We put a python installer into the build, and provide the GUI for user to install the python and tensorflow. This didn\u2019t work well when we tested on teammates' computers. One problem is there are many installation configurations, such as version, path,etc. Unknown problem will happen if users don\u2019t configure it in right way. Another problem is that some teammates already have installed the python in computer, but with different version and environment Prebuilt python environment into electron app (Final choice) To make the python environment more stable and convenient, we preinstall the whole python environment, including interpreter and dependencies, into the final executable. Even though the final build grew from 250MB into 1.6GB, the plan is much stable and under control. Build Cross Different Frameworks/Platforms Our project is an example of multiple frameworks and platforms. When we want to distribute our project by binaries, we consider two stages: 1. Prebuild : First stage is to build all modules in their native platforms, as we discussed in Unity, electron, and python. In our case, our biggest challenge is to build python codes. 2. Combination and Communication : When we say combine the build, it's mainly about how to manage the paths, how to read files in the build files. Almost all frameworks(in our case, Unity and Electron) have their own way to get dynamica relative path during runtime, so this is doable. As for the communication, because we use socket to do the inter-process communication. As long as we use the right port, the operating system will handle the rest. Develop Mode VS Runtime Mode Most frameworks have a way separate codes in development and codes in build. We have the same situation, because the way we find codes in other platforms is different between develop mode and build runtime. Now we need to manually redirect the codes(latest developer codes or codes in last version\u2019s build) during the development. This is very inconvenient and very easy to cause bugs. Our solution next step, is to automate the multi-platform build procedure, so that we manage the relationship between develop and build. Manual operation is the devil, we need to wipe this out of our build procedure!","title":"Build of Multiple Frameworks"},{"location":"game/Build/#build-of-multiple-frameworks","text":"We successfully packed everything, including unity, python, tensorflow, electron into one executable. So we can distribute our application easily to playtesters.","title":"Build of Multiple Frameworks"},{"location":"game/Build/#main-components-of-build","text":"When we work on unity, unity helps to build everything inside unity. When working on an electron, we use electron-forge to build everything in the electron. However, our application uses both unity,electron and python. And there are no official tools to build them together. Electron native build : We use electron-forge to build resources managed by electrons. The main difference between normal electron build and ours is that there are many resources not managed by electrons, such as unity codes and python codes. Unity executables : There are two unity executables. One is a GUI for playing the game, another is the record playback app. In an ideal situation, these 2 should be combined into one app. Since unity build is very small, build twice is acceptable in size. Python build : We discussed how to build python into unity in previous blogs(Week6). We analyze pros and cons on different approaches. We still use \u201cpython interpreter + source codes\u201d for the same reason Database These are all static files. Just copy it into the right directory.","title":"Main Components of Build"},{"location":"game/Build/#challenges-and-solutions","text":"","title":"Challenges and Solutions"},{"location":"game/Build/#build-python-environment","text":"Even we built our unity app by using \u201cpython interpreter + source codes\u201d for the source codes. We also need to consider the python environment.","title":"Build Python Environment"},{"location":"game/Build/#provide-installer-in-electron-app","text":"We put a python installer into the build, and provide the GUI for user to install the python and tensorflow. This didn\u2019t work well when we tested on teammates' computers. One problem is there are many installation configurations, such as version, path,etc. Unknown problem will happen if users don\u2019t configure it in right way. Another problem is that some teammates already have installed the python in computer, but with different version and environment","title":"Provide installer in electron app"},{"location":"game/Build/#prebuilt-python-environment-into-electron-app-final-choice","text":"To make the python environment more stable and convenient, we preinstall the whole python environment, including interpreter and dependencies, into the final executable. Even though the final build grew from 250MB into 1.6GB, the plan is much stable and under control.","title":"Prebuilt python environment into electron app (Final choice)"},{"location":"game/Build/#build-cross-different-frameworksplatforms","text":"Our project is an example of multiple frameworks and platforms. When we want to distribute our project by binaries, we consider two stages: 1. Prebuild : First stage is to build all modules in their native platforms, as we discussed in Unity, electron, and python. In our case, our biggest challenge is to build python codes. 2. Combination and Communication : When we say combine the build, it's mainly about how to manage the paths, how to read files in the build files. Almost all frameworks(in our case, Unity and Electron) have their own way to get dynamica relative path during runtime, so this is doable. As for the communication, because we use socket to do the inter-process communication. As long as we use the right port, the operating system will handle the rest.","title":"Build Cross Different Frameworks/Platforms"},{"location":"game/Build/#develop-mode-vs-runtime-mode","text":"Most frameworks have a way separate codes in development and codes in build. We have the same situation, because the way we find codes in other platforms is different between develop mode and build runtime. Now we need to manually redirect the codes(latest developer codes or codes in last version\u2019s build) during the development. This is very inconvenient and very easy to cause bugs. Our solution next step, is to automate the multi-platform build procedure, so that we manage the relationship between develop and build. Manual operation is the devil, we need to wipe this out of our build procedure!","title":"Develop Mode VS Runtime Mode"},{"location":"game/DataVisualization/","text":"Data visualization Data visualization might be the most important part of this app. However, drawing graphics, especially interactive one, is not as same as that in game engines. Naive/Low-level solutions One solution is draw data graphics by using svg, since html standards support this format. Or we can use some libraries like webGL. Even though we can have highly customized graphics to show our data, building a data visualization module from scratch is overscoped because we only have a few weeks to finish the whole app. Javascript Data Visualization Library Javascript has many data visualization libraries. We finally choose d3.js (https://github.com/d3/d3 ) among others for 2 reasons: 1. Independent: Many other data visualization libraries( such as Victory, Rechard,etc) only work with some front-end frameworks like React and Vue. d3.js easter to integrate since it only needs javascript 2. Community resoruces\uff1a Many templates and tutorials of d3.js on the internet.","title":"Data visualization"},{"location":"game/DataVisualization/#data-visualization","text":"Data visualization might be the most important part of this app. However, drawing graphics, especially interactive one, is not as same as that in game engines.","title":"Data visualization"},{"location":"game/DataVisualization/#naivelow-level-solutions","text":"One solution is draw data graphics by using svg, since html standards support this format. Or we can use some libraries like webGL. Even though we can have highly customized graphics to show our data, building a data visualization module from scratch is overscoped because we only have a few weeks to finish the whole app.","title":"Naive/Low-level solutions"},{"location":"game/DataVisualization/#javascript-data-visualization-library","text":"Javascript has many data visualization libraries. We finally choose d3.js (https://github.com/d3/d3 ) among others for 2 reasons: 1. Independent: Many other data visualization libraries( such as Victory, Rechard,etc) only work with some front-end frameworks like React and Vue. d3.js easter to integrate since it only needs javascript 2. Community resoruces\uff1a Many templates and tutorials of d3.js on the internet.","title":"Javascript Data Visualization Library"},{"location":"game/DesktopGUI/","text":"Desktop GUI for designers We plan to develop an app for everything, including AI Module, Unity frontend, python gameplay, card/deck editing, data visualization, etc. Motivations Accessible to designers After half, we start to think about how to help designers. We need a user friendly GUI to let designers use all the tools we provide. Organize our tools chain We have many tools in different platforms using different techniques. When we try to build more and more tools, it is a chance to organize our tool chain. Schemes We have sevarl choices to develop our desktop GUI Unity Built-in UI System Pros Our game GUI is developed in Unity, and we are familiar with Unity! Cons Unity\u2019s UI system is not designed for generalized desktop GUI. This would be a big problem when we try to build complex UI such as data visualization. Browser + HTML + CSS + JS Pros Easy to use, only need a browser. Easy to develop, web techniques are convenient and have many libraries and frameworks. Cons Browsers usually don\u2019t support manipulating local files and start other .exe in another process, which are important to us. Electron(final choice) We finnal chose electron for several reasons: - Use web standards: Developing a desktop app is basically the same as writing a website in electron. It uses html, javascript and css, and we are already familiar with these techniques. - Highlevel, lightweight: Because of html and javascript, developing an app is much easier than other techniques such as windows naive API, Qt, etc.","title":"Desktop GUI for designers"},{"location":"game/DesktopGUI/#desktop-gui-for-designers","text":"We plan to develop an app for everything, including AI Module, Unity frontend, python gameplay, card/deck editing, data visualization, etc.","title":"Desktop GUI for designers"},{"location":"game/DesktopGUI/#motivations","text":"","title":"Motivations"},{"location":"game/DesktopGUI/#accessible-to-designers","text":"After half, we start to think about how to help designers. We need a user friendly GUI to let designers use all the tools we provide.","title":"Accessible to designers"},{"location":"game/DesktopGUI/#organize-our-tools-chain","text":"We have many tools in different platforms using different techniques. When we try to build more and more tools, it is a chance to organize our tool chain.","title":"Organize our tools chain"},{"location":"game/DesktopGUI/#schemes","text":"We have sevarl choices to develop our desktop GUI","title":"Schemes"},{"location":"game/DesktopGUI/#unity-built-in-ui-system","text":"","title":"Unity Built-in UI System"},{"location":"game/DesktopGUI/#pros","text":"Our game GUI is developed in Unity, and we are familiar with Unity!","title":"Pros"},{"location":"game/DesktopGUI/#cons","text":"Unity\u2019s UI system is not designed for generalized desktop GUI. This would be a big problem when we try to build complex UI such as data visualization.","title":"Cons"},{"location":"game/DesktopGUI/#browser-html-css-js","text":"","title":"Browser + HTML + CSS + JS"},{"location":"game/DesktopGUI/#pros_1","text":"Easy to use, only need a browser. Easy to develop, web techniques are convenient and have many libraries and frameworks.","title":"Pros"},{"location":"game/DesktopGUI/#cons_1","text":"Browsers usually don\u2019t support manipulating local files and start other .exe in another process, which are important to us.","title":"Cons"},{"location":"game/DesktopGUI/#electronfinal-choice","text":"We finnal chose electron for several reasons: - Use web standards: Developing a desktop app is basically the same as writing a website in electron. It uses html, javascript and css, and we are already familiar with these techniques. - Highlevel, lightweight: Because of html and javascript, developing an app is much easier than other techniques such as windows naive API, Qt, etc.","title":"Electron(final choice)"},{"location":"game/Overview/","text":"Overview This section is about engineering. During the project, we explore how to integrate AI into the process of traditional game development. We met mang challenges and learned many experiences. So we put the experiences we think can be applied to the general case into this section. If someone asked \u201cI want to develop a game using AI to playtest, how to do this?\u201d, then this section is one part of the answer. AI as tool in game development We treat AI as a tool for the development team. Compared to other tools, this is more complex. The biggest reason making our AI tools so different is that it needs access to gameplay logic. In other words, it requires gameplay programmers to provide formatted APIs to AI, which is challenging because gameplay keeps changing during the development process. Challenges One codes for all situations In our project, we have a game for players, a game for AI, and a game for playtest. In read production, the game itself keeps changing, so we cannot maintain 3 versions of games. Instead, we have one single version that can be played in different situations. Generialization Because we want designers to get quick feedback on his design, we aim to reduce the communication between designers, playtesters and programmers. We need to make our AI and game generalized enough so that we can build a tool, like our demo, designer can use this tool design and get feedback.","title":"Overview"},{"location":"game/Overview/#overview","text":"This section is about engineering. During the project, we explore how to integrate AI into the process of traditional game development. We met mang challenges and learned many experiences. So we put the experiences we think can be applied to the general case into this section. If someone asked \u201cI want to develop a game using AI to playtest, how to do this?\u201d, then this section is one part of the answer.","title":"Overview"},{"location":"game/Overview/#ai-as-tool-in-game-development","text":"We treat AI as a tool for the development team. Compared to other tools, this is more complex. The biggest reason making our AI tools so different is that it needs access to gameplay logic. In other words, it requires gameplay programmers to provide formatted APIs to AI, which is challenging because gameplay keeps changing during the development process.","title":"AI as tool in game development"},{"location":"game/Overview/#challenges","text":"","title":"Challenges"},{"location":"game/Overview/#one-codes-for-all-situations","text":"In our project, we have a game for players, a game for AI, and a game for playtest. In read production, the game itself keeps changing, so we cannot maintain 3 versions of games. Instead, we have one single version that can be played in different situations.","title":"One codes for all situations"},{"location":"game/Overview/#generialization","text":"Because we want designers to get quick feedback on his design, we aim to reduce the communication between designers, playtesters and programmers. We need to make our AI and game generalized enough so that we can build a tool, like our demo, designer can use this tool design and get feedback.","title":"Generialization"},{"location":"game/Summary/","text":"Summary How this architecture solved the challenges mentioned in 'Overview'? We decoupled the gameplay logic to a individual module, so both player GUI, AI, playtesting can use this module with same APIs. And we also try to make our gameplay and AI as generized as possible. After doing this, we separate the everything configurable into a persistence layer. By quering and updateing the data in persistence layer, designer can change the game, train AI and get playtest data without writing codes. What is the biggest difference compared to traditional game development? We found the we write gameplay codes is very different. When we develop a game in game engine such as Unity, we write all gameplay, graphics, physics , VFX,etc in game enigne. However, because our game need to run both with graphic and without graphic. Separate gameplay logics from game engine and put it into another platform and language is challenging. If we want to develop a game with AI to do the playtesting, can we just follow this architecture? Situations could be very different on different games, so it is hard to have one solution can applied to anycase. However, we think that \"six modules\" (AI/ Gameplay/ Database/PlayerGUI/ DataVisualization/ DesignerGUI) represent six general problems every game will meet if it want to use AI to playtest.","title":"Summary"},{"location":"game/Summary/#summary","text":"","title":"Summary"},{"location":"game/Summary/#how-this-architecture-solved-the-challenges-mentioned-in-overview","text":"We decoupled the gameplay logic to a individual module, so both player GUI, AI, playtesting can use this module with same APIs. And we also try to make our gameplay and AI as generized as possible. After doing this, we separate the everything configurable into a persistence layer. By quering and updateing the data in persistence layer, designer can change the game, train AI and get playtest data without writing codes.","title":"How this architecture solved the challenges mentioned in 'Overview'?"},{"location":"game/Summary/#what-is-the-biggest-difference-compared-to-traditional-game-development","text":"We found the we write gameplay codes is very different. When we develop a game in game engine such as Unity, we write all gameplay, graphics, physics , VFX,etc in game enigne. However, because our game need to run both with graphic and without graphic. Separate gameplay logics from game engine and put it into another platform and language is challenging.","title":"What is the biggest difference compared to traditional game development?"},{"location":"game/Summary/#if-we-want-to-develop-a-game-with-ai-to-do-the-playtesting-can-we-just-follow-this-architecture","text":"Situations could be very different on different games, so it is hard to have one solution can applied to anycase. However, we think that \"six modules\" (AI/ Gameplay/ Database/PlayerGUI/ DataVisualization/ DesignerGUI) represent six general problems every game will meet if it want to use AI to playtest.","title":"If we want to develop a game with AI to do the playtesting, can we just follow this architecture?"},{"location":"game/Unity/","text":"Use Unity To Develop the Player GUI Key features of Unity front-end Decoupled front-end : Front-end includes all animations, UI, and graphics, but shouldn\u2019t have anything to control the gameplay logic. Data-driven rendering : Rendering of the game is based on data, just like browsers render the HTML. So when we change game logic in python, the rendering part would change according to the data sent back from python. So that we don\u2019t need to change the coeds to much Art resources hot update : Art-side resources shouldn\u2019t be embedded in the application. All of them are configurable and can be hot updated. So when it provided as tools, result can be immediately seen without restart the application, after we change the art resources Frontend&Backend Architecture The architecture largely inspired by the modern web stack: HTML/Browser/CSS/JS. Because we have a similar situation. Instead of a game application, Unity-side, more like a renderer, it renders the information from the python module, and gathers user input sent back to python. It is very similar to the relationship between browser and server. Frontend Rendering Same as browser render website by HTML file, we have our own \u201cMarkup language\u201d for unity to render. This markup language is much simpler than HTML because it does not try to be general, but only used in this type of game. Biggest difference between HTML and ours is that our markup not only has to consider the static things, but also event sequence, animation. Unity also generates the animation based on the game event in markup. This graphic shows how a markup file in response message is rendered to final elements on the screen. Frontend Animation Challenges In a normal unity game, doing animation is easy since we can get all gameobject instances we want to do animations with. But our game is running in python, all the object instances are stored in python runtime. An object instance sharing mechanism is hard to fit into our current request/response architecture between C#/C++ Solutions We extend our \u201cmarkup-language\u201d to support animation. All the markups in one \u201cgame sequence markup file\u201d share the same ID space, so they can find instance by those ID C#/Python Protocol-based Communication Under this architecture, the communication between C# and Python is very clear, C# send request message to Python, Python send response message to C#. Because request always includes Userinput and response always includes GameSequenceMarkup, we simplified the communication by introducing this architecture!","title":"Unity"},{"location":"game/Unity/#use-unity-to-develop-the-player-gui","text":"","title":"Use Unity To Develop the Player GUI"},{"location":"game/Unity/#key-features-of-unity-front-end","text":"Decoupled front-end : Front-end includes all animations, UI, and graphics, but shouldn\u2019t have anything to control the gameplay logic. Data-driven rendering : Rendering of the game is based on data, just like browsers render the HTML. So when we change game logic in python, the rendering part would change according to the data sent back from python. So that we don\u2019t need to change the coeds to much Art resources hot update : Art-side resources shouldn\u2019t be embedded in the application. All of them are configurable and can be hot updated. So when it provided as tools, result can be immediately seen without restart the application, after we change the art resources","title":"Key features of  Unity front-end"},{"location":"game/Unity/#frontendbackend-architecture","text":"The architecture largely inspired by the modern web stack: HTML/Browser/CSS/JS. Because we have a similar situation. Instead of a game application, Unity-side, more like a renderer, it renders the information from the python module, and gathers user input sent back to python. It is very similar to the relationship between browser and server.","title":"Frontend&amp;Backend Architecture"},{"location":"game/Unity/#frontend-rendering","text":"Same as browser render website by HTML file, we have our own \u201cMarkup language\u201d for unity to render. This markup language is much simpler than HTML because it does not try to be general, but only used in this type of game. Biggest difference between HTML and ours is that our markup not only has to consider the static things, but also event sequence, animation. Unity also generates the animation based on the game event in markup. This graphic shows how a markup file in response message is rendered to final elements on the screen.","title":"Frontend Rendering"},{"location":"game/Unity/#frontend-animation","text":"","title":"Frontend Animation"},{"location":"game/Unity/#challenges","text":"In a normal unity game, doing animation is easy since we can get all gameobject instances we want to do animations with. But our game is running in python, all the object instances are stored in python runtime. An object instance sharing mechanism is hard to fit into our current request/response architecture between C#/C++","title":"Challenges"},{"location":"game/Unity/#solutions","text":"We extend our \u201cmarkup-language\u201d to support animation. All the markups in one \u201cgame sequence markup file\u201d share the same ID space, so they can find instance by those ID","title":"Solutions"},{"location":"game/Unity/#cpython-protocol-based-communication","text":"Under this architecture, the communication between C# and Python is very clear, C# send request message to Python, Python send response message to C#. Because request always includes Userinput and response always includes GameSequenceMarkup, we simplified the communication by introducing this architecture!","title":"C#/Python Protocol-based Communication"}]}